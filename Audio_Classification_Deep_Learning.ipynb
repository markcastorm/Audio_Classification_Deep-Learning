{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMixKXFBqtlrTS9tPtI8tOA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markcastorm/Audio_Classification_Deep-Learning/blob/main/Audio_Classification_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Audio Classification using DeepLearning**"
      ],
      "metadata": {
        "id": "tulwN74_81iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import and installing Dependancies"
      ],
      "metadata": {
        "id": "-UZwFIeR9CC8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB5IyWKsynoJ"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 tensorflow-io matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Lets Load Dependencies"
      ],
      "metadata": {
        "id": "0UWumyaf9-lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from matplotlibimport pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio"
      ],
      "metadata": {
        "id": "ipBgqjYJ96G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Lets Build a Loading Function\n",
        "\n",
        "First we define paths to our files"
      ],
      "metadata": {
        "id": "awhIL1CUFlIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CAPUCHIN_FILE = os.path.join('data', 'Parsed_Capuchinbird_Clips', 'XC3776-3.wav')\n",
        "NOT_CAPUCHIN_FILE = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips', 'afternoon-birds-song-in-forest-0.wav')"
      ],
      "metadata": {
        "id": "4f--p9lCGWd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next part we are gonna build a data loading function"
      ],
      "metadata": {
        "id": "pYy4C6JGI38V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_wav_16k_mono(filename):\n",
        "  #loading the encoded wav file\n",
        "  file_contents = tf.io.read_file(filename)\n",
        "  #Decode wav (tensor by Channels)\n",
        "  wav, sample_rate = tf.audio.decode_wav(file_contents,desired_channels=1)\n",
        "  #Removing the trailling axis\n",
        "  wav = tf.squeeze(wav, axis=-1)\n",
        "  sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "  wav = tfio.audio.resample(wav, rate_in sample_rate, rate_out=16000)\n",
        "  return wav"
      ],
      "metadata": {
        "id": "ZxDp6dvjJAzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets visualize the wave"
      ],
      "metadata": {
        "id": "aPyfuJczMHaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wave =  load_wav_16k_mono(CAPUCHIN_FILE)\n",
        "nwave = load_way_16k-mono(NOT_CAPUCHIN_FILE)"
      ],
      "metadata": {
        "id": "nKNe7Pz9MM8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(wave)\n",
        "plt.plot(nwave)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sxGRdvEZUwFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Now Lets Create A Tensorflow Dataset\n",
        "\n",
        "\n",
        "First we define the paths to the Positive and Negative Data"
      ],
      "metadata": {
        "id": "2yY7r1QFU_9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "POS = os.path.join('data', 'Parsed_Capuchinbird_Clips')\n",
        "NEG = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips')"
      ],
      "metadata": {
        "id": "N5aSWEKfVw-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets make the tensorflow Datasets"
      ],
      "metadata": {
        "id": "FfDMpxygdMHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos = tf.data.Dataset.list_files(POS+'\\*.wav')\n",
        "neg = tf.data.Dataset.list_files(NEG+'\\*.wav')"
      ],
      "metadata": {
        "id": "ZR38vDvGdS4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding labels and Combine Positive and Negative Data Samples"
      ],
      "metadata": {
        "id": "Kun4oXHdd78C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
        "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
        "data = positives.concatenate(negatives)\n"
      ],
      "metadata": {
        "id": "d-zloSmgeWMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Lets determine the Average Length of Capuchin Capuchin Call\n",
        "\n",
        "Lets calculate the wave cycle length"
      ],
      "metadata": {
        "id": "ACBoCV_EiFpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = []\n",
        "for file in os.listdir(os.path.join('data', 'Parsed_Capuchinbird_Clips')):\n",
        "    tensor_wave = load_wav_16k_mono(os.path.join('data', 'Parsed_Capuchinbird_Clips', file))\n",
        "    lengths.append(len(tensor_wave))"
      ],
      "metadata": {
        "id": "LLzUUG4kinyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are calculating Mean, Min and Max"
      ],
      "metadata": {
        "id": "6WbS_mXxkBR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " tf.math.reduce_mean(lengths)\n",
        "tf.math.reduce_min(lengths)\n",
        "tf.math.reduce_max(lengths)"
      ],
      "metadata": {
        "id": "KrRpsGc_kAl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now lets Build a Processing Function to Convert to a Spectogram\n",
        "\n",
        "\n",
        "First off lets start by building the Preprocessing Function"
      ],
      "metadata": {
        "id": "d1Ojs952n0Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_path, label):\n",
        "    wav = load_wav_16k_mono(file_path)\n",
        "    wav = wav[:48000]\n",
        "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
        "    wav = tf.concat([zero_padding, wav],0)\n",
        "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "    return spectrogram, label\n"
      ],
      "metadata": {
        "id": "ovurWGmSoRF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets tests out the function"
      ],
      "metadata": {
        "id": "KDk4d7Tx-_Pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()\n"
      ],
      "metadata": {
        "id": "oILtFMdR--m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectrogram, label = preprocess(filepath, label)"
      ],
      "metadata": {
        "id": "SOldnwlPD3cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30,20))\n",
        "plt.imshow(tf.transpose(spectrogram)[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yFIvj6-1EE9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the testing and training Partition\n",
        "\n",
        "Lets create a Tensorflow Data Pipeline"
      ],
      "metadata": {
        "id": "o9phuBzQEhMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.map(preprocess)\n",
        "data = data.cache()\n",
        "data =shuffle(buffer_size=1000)\n",
        "data = data.batch(16)\n",
        "data = data.prefetch(8)"
      ],
      "metadata": {
        "id": "M6GxpeF6E7-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets split the data into train and test sets"
      ],
      "metadata": {
        "id": "-te22JR4VhHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples, labels = train.as_numpy_iterator().next()\n"
      ],
      "metadata": {
        "id": "dTJPsIbbXLxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples.shape"
      ],
      "metadata": {
        "id": "fM8Qhvxda6hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building the Deep Learning Models"
      ],
      "metadata": {
        "id": "3Nv6Oneca-wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
      ],
      "metadata": {
        "id": "xN7qjgx3bLge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets build the sequential Model"
      ],
      "metadata": {
        "id": "yCSZr8xFeoy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = sequential()\n",
        "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491, 257,1)))\n",
        "model.add(Conv2D(16, (3,3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "1eq-o5zYeyYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
      ],
      "metadata": {
        "id": "j4eWcgkTCZ2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "HleYahekC6dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the Model"
      ],
      "metadata": {
        "id": "eQWzc3E5C_a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(train, epochs=4, validation_data=test)"
      ],
      "metadata": {
        "id": "C_LKwsaXC-cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(hist.history['loss'],'r')\n",
        "plt.plot(hist.history['val_loss'], 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q6VlB6IqSL9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Precision')\n",
        "plt.plot(hist.history['precision'],'r')\n",
        "plt.plot(hist.history['val_precision'], 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QweWdBjLo_ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Recall')\n",
        "plt.plot(hist.history['recall'],'r')\n",
        "plt.plot(hist.history['val_recall'], 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rBOs3joppCdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets test out our modell and make a single prediction"
      ],
      "metadata": {
        "id": "TwLwGaj5pmik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = test.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "ZVEEy0KQpvSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(X_test)"
      ],
      "metadata": {
        "id": "C7thEGqqqUdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now how about we convert the logits to classes"
      ],
      "metadata": {
        "id": "JvJJsA-tqnJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
      ],
      "metadata": {
        "id": "FJdvx2lqqt3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a Forest Parsing Function"
      ],
      "metadata": {
        "id": "XPBLGZd1rGFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets load up the MP3s"
      ],
      "metadata": {
        "id": "pfFv5uhbrMru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mp3_16k_mono(filename):\n",
        "  res - tfio.audio.AudioIOTensor(filename)\n",
        "  tensor = res,to_tensor()\n",
        "  tensor = tf.math.reduce_sum(tensor, axis=1) / 2\n",
        "  sample_rate = res.rate\n",
        "  sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "  wav = tfio.audio.resample(tensor, rate_sample_rate, rate_out=16000)\n",
        "  return wav"
      ],
      "metadata": {
        "id": "nbTrlO53rFAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp3 = os.path.join('data', 'Forest Recordings', 'recording_00.mp3')"
      ],
      "metadata": {
        "id": "ddKlWodIrLkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wav = load_mp3_16k_mono(mp3)"
      ],
      "metadata": {
        "id": "y02PzdDT87HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)"
      ],
      "metadata": {
        "id": "WkFF2Nx5U14u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples,index  = audio_slices.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "Jo6GPHVOaBQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets build a function to convert clips into windowed spectrograms"
      ],
      "metadata": {
        "id": "M2Xve7LtPsQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_mp3(sample, index):\n",
        "  sample = sample[0]\n",
        "  zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32)\n",
        "  wav = tf.concat([zero_padding, sample], 0)\n",
        "  spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "  spectrogram = tf.abs(spectrogram)\n",
        "  spectrogram = tf.expand_dims(spectrogam, axis=2)\n",
        "  return spectrogram"
      ],
      "metadata": {
        "id": "9pSqn7AuP6Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets do the convertion and make predictions"
      ],
      "metadata": {
        "id": "8GRbfnz7Rm-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=16000, sequence_stride=16000, batch_size=1)\n",
        "audio_slices = audio_slices.map(preprocess_mp3)\n",
        "audio_slices = audio_slices.batch(64)"
      ],
      "metadata": {
        "id": "el5NaPPjR1rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(audio_slices)\n",
        "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
      ],
      "metadata": {
        "id": "Np4bzqUeSxOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets group the predictions"
      ],
      "metadata": {
        "id": "Kznr3nrdUPsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import groupby\n",
        "\n",
        "yhat = [key for key, group in groupby(yhat)]\n",
        "calls = tf.math.reduce_sum(yhat).numpy()"
      ],
      "metadata": {
        "id": "voFIJDk_UXUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calls"
      ],
      "metadata": {
        "id": "QIo5dw9cUytS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a loop to go through the recording and making predictions"
      ],
      "metadata": {
        "id": "qestDucSU4ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = {}\n",
        "for file in os.listdir(os.path.join('data', 'Forest Recordings')):\n",
        "  FILEPATH = os.path.join('data', 'Forest Recordings', file)\n",
        "\n",
        "  wav = load_mp3_16k_mono(FILEPATH)\n",
        "  audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
        "  audio_slices = audio_slices.map(preprocess_mp3)\n",
        "  audio_slices = audio_slices.batch(64)\n",
        "  yhat = model.predict(audio_slices)\n",
        "  results[file] = yhat"
      ],
      "metadata": {
        "id": "U1hxMbdkU3_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "NZc6w-ejW9qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Lets convert the predictions into Classes"
      ],
      "metadata": {
        "id": "Skd-vONAXA6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_preds = {}\n",
        "for file, logits in results.items():\n",
        "  class_preds[file] = [1 if prediction > 0.99 else 0 for predictions in logits]\n",
        "class_preds"
      ],
      "metadata": {
        "id": "Zm7K64QgXODm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fainaly lets do the group consecutive Detection"
      ],
      "metadata": {
        "id": "VoWdZoiiX1_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "postprocessed = {}\n",
        "for file, scores in class_preds.items():\n",
        "  postprocessed[file] = tf.math.reduce_sum([key for key, group in groupby(scores)]).numpy()\n",
        "postprocessed\n"
      ],
      "metadata": {
        "id": "LUf7GdMzYkbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export Results"
      ],
      "metadata": {
        "id": "hTxJSj_9bgN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "with open('results.csv', 'w', newline='') as f:\n",
        "  writer = csv.writer(f, delimiter=',')\n",
        "  writer.writerow(['recording', 'caapuchin_calls'])\n",
        "  for key, value in postprocessed.items():\n",
        "    writer.writerow([key, value])"
      ],
      "metadata": {
        "id": "ZMY1jN5Tbn6s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}